В методе `train` класса `NaiveBayesModel` реализован алгоритм обучения наивного Байесовского классификатора. Вот более
детальное объяснение шагов алгоритма:

1. **Расчет вероятностей классов:**
    - `total_count` - общее количество тренировочных примеров.
    - `spam_count` - количество примеров, отмеченных как "spam".

   Вычисляются вероятности классов:
    - Вероятность класса "spam" (`self.class_probabilities["spam"]`) - отношение числа "spam" примеров к общему числу
      примеров.
    - Вероятность класса "ham" (`self.class_probabilities["ham"]`) - оставшаяся часть (не "spam").

2. **Расчет вероятностей слов:**
    - `spam_words` и `ham_words` - словари, в которых ключи - слова, а значения - количество раз, которое каждое слово
      встречается в соответствующем классе ("spam" или "ham").
    - `self.spam_words` - множество слов, характерных для "spam".

   Итерация по тренировочным данным:
    - Извлекаются класс (`_class`) и текст (`text`) из каждой записи.
    - Слова в тексте извлекаются с использованием статического метода `get_words`, а затем удаляются нейтральные
      слова (`self.NEUTRAL_WORDS`).
    - Для каждого слова в тексте обновляются соответствующие счетчики в `spam_words` или `ham_words`.

3. **Расчет вероятностей слов для каждого класса:**
    - Итерация по объединению множества ключей из `spam_words` и `ham_words`.
    - Расчет вероятностей слов для "spam" и "ham" классов:
        - `self.word_probabilities["spam"][word]` - вероятность слова в классе "spam".
        - `self.word_probabilities["ham"][word]` - вероятность слова в классе "ham".

   Вероятности рассчитываются с использованием формулы Laplace Smoothing, чтобы избежать проблемы с нулевыми
   вероятностями.
    - **Laplace Smoothing (или Add-One Smoothing)** - это метод сглаживания вероятностей, применяемый для избежания
      нулевых
      вероятностей, особенно в контексте наивных Байесовских классификаторов. Этот метод заключается в добавлении
      небольшой
      константы к счетчикам, чтобы предотвратить проблему, когда событие не встречается в обучающих данных. Формула
      Laplace
      Smoothing используется для пересчета вероятностей слов в классах, чтобы учесть все возможные слова и сделать
      модель
      более устойчивой к отсутствию данных.
